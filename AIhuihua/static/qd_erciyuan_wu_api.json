{
  "55": {
    "inputs": {
      "seed": [
        "132",
        3
      ],
      "steps": 20,
      "cfg": 7,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 0.4,
      "preview_method": "auto",
      "vae_decode": "true",
      "model": [
        "138",
        0
      ],
      "positive": [
        "112",
        1
      ],
      "negative": [
        "112",
        2
      ],
      "latent_image": [
        "143",
        0
      ],
      "optional_vae": [
        "112",
        4
      ]
    },
    "class_type": "KSampler (Efficient)"
  },
  "112": {
    "inputs": {
      "ckpt_name": "CounterfeitV30_v30.safetensors",
      "vae_name": "Baked VAE",
      "clip_skip": -2,
      "lora_name": "None",
      "lora_model_strength": 0.4,
      "lora_clip_strength": 0.4,
      "positive": [
        "141",
        0
      ],
      "negative": "embedding:verybadimagenegative_v1.3, embedding:EasyNegative",
      "token_normalization": "none",
      "weight_interpretation": "comfy",
      "empty_latent_width": [
        "127",
        0
      ],
      "empty_latent_height": [
        "127",
        1
      ],
      "batch_size": 1,
      "cnet_stack": [
        "131",
        0
      ]
    },
    "class_type": "Efficient Loader"
  },
  "123": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "scale_by": 0.4,
      "image": [
        "129",
        0
      ]
    },
    "class_type": "ImageScaleBy"
  },
  "127": {
    "inputs": {
      "image": [
        "123",
        0
      ]
    },
    "class_type": "GetImageSize"
  },
  "129": {
    "inputs": {
      "image": "1-äºº8.jpg",
      "choose file to upload": "image"
    },
    "class_type": "LoadImage"
  },
  "131": {
    "inputs": {
      "switch_1": "On",
      "controlnet_1": "control_v11p_sd15_canny.pth",
      "controlnet_strength_1": 0.9,
      "start_percent_1": 0,
      "end_percent_1": 1,
      "switch_2": "Off",
      "controlnet_2": "None",
      "controlnet_strength_2": 0.9,
      "start_percent_2": 0,
      "end_percent_2": 1,
      "switch_3": "Off",
      "controlnet_3": "None",
      "controlnet_strength_3": 0.4,
      "start_percent_3": 0,
      "end_percent_3": 1,
      "image_1": [
        "133",
        0
      ]
    },
    "class_type": "CR Multi-ControlNet Stack"
  },
  "132": {
    "inputs": {
      "seed": 775114389095858
    },
    "class_type": "Seed"
  },
  "133": {
    "inputs": {
      "low_threshold": 100,
      "high_threshold": 200,
      "resolution": 512,
      "image": [
        "123",
        0
      ]
    },
    "class_type": "CannyEdgePreprocessor"
  },
  "138": {
    "inputs": {
      "weight": 0.8,
      "noise": 0,
      "weight_type": "original",
      "start_at": 0,
      "end_at": 1,
      "unfold_batch": false,
      "ipadapter": [
        "139",
        0
      ],
      "clip_vision": [
        "140",
        0
      ],
      "image": [
        "123",
        0
      ],
      "model": [
        "112",
        0
      ]
    },
    "class_type": "IPAdapterApply"
  },
  "139": {
    "inputs": {
      "ipadapter_file": "ip-adapter_sd15_plus.pth"
    },
    "class_type": "IPAdapterModelLoader"
  },
  "140": {
    "inputs": {
      "clip_name": "SD1.5/pytorch_model.bin"
    },
    "class_type": "CLIPVisionLoader"
  },
  "141": {
    "inputs": {
      "model": "wd-v1-4-convnextv2-tagger-v2",
      "threshold": 0.35,
      "character_threshold": 0.85,
      "exclude_tags": "",
      "image": [
        "129",
        0
      ]
    },
    "class_type": "WD14Tagger|pysssss"
  },
  "143": {
    "inputs": {
      "pixels": [
        "123",
        0
      ],
      "vae": [
        "112",
        4
      ]
    },
    "class_type": "VAEEncode"
  },
  "144": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "55",
        5
      ]
    },
    "class_type": "SaveImage"
  }
}